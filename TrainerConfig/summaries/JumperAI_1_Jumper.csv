Steps,Policy/Entropy,High Score,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
10000,0.6396764,9.0,14.80190174326466,-0.35834828,-0.909350229188115,-0.909350229188115,0.14933074,0.077056766,0.00029996916,1.0
20000,0.41124123,None,31.72875816993464,-0.7570711,-0.9215686180525355,-0.9215686180525355,0.01753392,0.06490706,0.0002999135,1.0
30000,0.20697561,None,64.29220779220779,-0.6860012,-0.9385620845493927,-0.9385620845493927,0.014195183,0.06281306,0.00029985135,1.0
40000,0.08096013,None,109.92222222222222,-0.58929396,-0.9366666617492835,-0.9366666617492835,0.011286644,0.06776308,0.00029978895,1.0
50000,0.055471435,None,136.47222222222223,-0.51691985,-0.9301369809736945,-0.9301369809736945,0.012621159,0.068696156,0.00029972682,1.0
60000,0.047819506,None,136.55555555555554,-0.48202017,-0.9374999959642688,-0.9374999959642688,0.013503746,0.06842185,0.00029967065,1.0
70000,0.04170037,None,173.6551724137931,-0.46035254,-0.9051724092970634,-0.9051724092970634,0.01263403,0.06968988,0.0002996145,1.0
80000,0.03964668,None,162.01639344262296,-0.45107326,-0.9065573723589788,-0.9065573723589788,0.01371864,0.06855235,0.0002995523,1.0
90000,0.03817105,None,162.06666666666666,-0.41995955,-0.9133333298067252,-0.9133333298067252,0.01492863,0.0709646,0.00029949026,1.0
100000,0.04163853,None,260.8421052631579,-0.36750013,-0.7973684139157596,-0.7973684139157596,0.014065462,0.06826731,0.00029942792,1.0
110000,0.03557439,16.0,551.9444444444445,-0.26809156,-0.4388888705935743,-0.4388888705935743,0.008700211,0.059820056,0.00029936558,1.0
120000,0.034964506,None,467.42857142857144,-0.17279226,-0.5285714130316462,-0.5285714130316462,0.012372275,0.06535802,0.0002993094,1.0
130000,0.033406407,18.0,587.6111111111111,-0.11884015,-0.48235292425926996,-0.48235292425926996,0.011729892,0.0656269,0.0002992532,1.0
